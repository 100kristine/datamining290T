* Obtaining Data :slide:

* Ways to Collect :slide:two_col:
  + Operational Data
  + Data Warehouse
  + Unstructured Data
  + External API
  + Data Sets

[[file:img/bottlecaps.jpg]]

** Operational Data :slide:
   + Most frequent in industry
   + Usually stored in databases best suited for transactional use
   + Challenge is reorganizing data to suit question
*** Data from production :notes:
    + Most frequently you'll have data that is being used by the application,
      and you'll want to find insights in it
    + We'll go into more detail in another class, but online use is
      optimized for small queries and small updates
    + Frequently just accessing the data in bulk is a software engineering
      problem:
      + ensuring long queries don't hold up production usage
      + joining across databases via software
      + understanding esoteric columns, like "flags"
    + Often will want to reorganize data to look like transactional
    + img: http://woodwarddesign.ca/blog/2009/03/06/bottle-caps/

** Example :slide:
   + Find the user names with most "liked" reviews on Yelp

users
| userID | name | flags |
| 25234   | Jim  | 0x200 |

reviews
| reviewID | businessID | userID | stars | text | flags |
| 282       | 52432       | 25234 |   4     | great place! | 0x1 |


feedback
| reviewID | srcUserID | ufcFlags | flags |
| 282       | 8205 | 0x1 | 0x0 |

*** Distributed Data :notes:
   + At Yelp we have a variety of database tables, and those tables can be
     spread across different databases
   + At a minimum we frequently need to =JOIN= across tables to answer queries
     + eg. matching up user names with reviews from separate tables
   + It is possible the review table is only indexed on business ID, and so
     finding all reviews by a user is really disk intensive: make sure you're
     not slowing down the whole site!
   + An additional challenge is when the "feedback" tables are in a separate
     database: can no longer issue normal SQL queries
   + What are these "flag" columns for?
   + Exactly: no one knows. Often must look into code, or compare data to
     production representation to guess meaning. In Yelp, =0x1= often means
     "inactive", so we probably don't want to count that feedback

** Data Warehouse :slide:two_col:
   + Data located on same system
   + Organized for analytics queries
   + Requires extra maintenance and understanding of construction

   [[file:img/Ikea-Warehouse.jpg]]
*** No free lunch :notes:
   + A strong data warehouse can be a big improvement over operational data
   + Hopefully, someone has already cleaned, joined data in a way that makes
     sense!
   + Optimized for long running queries: less fear of brining down website!
   + But you must learn how that process was accomplished in order to understand
     potential problems
   + How to handle missing data?
   + We'll go into more detail about how data warehouse schemas compare to
     online ones later in the course

** Unstructured :slide:
   + Haphazard collection of data
   + Unclear what structure should be
   + Examples: Web logs, text, multimedia
   + Must extract structure eventually
*** Yelp JSON logs :notes:
    + When developing a web application, new context or details become
      important: how long did certain requests take? What link did a user follow
      to a website?
    + Relational Databases aren't well suited for these wide varieties of
      potential attributes that don't apply to all items
    + So the current work around is just to write all useful information down in
      a log, and extract what is needed later
    + Text, like business reviews, another example: desired structure changes
      radically between questions: How many words? Characters? What is the sentiment?
    + Pictures can contain attributes like color depth, length, width
    + First step of data mining is often imposing structure on data: the data is
      not inherently unstructured, it just is unclear what the structure *should be*
      until query time

** Search Logs Example :slide:
#+begin_src log
193.139.1 jim [10/Oct/2013:13:55:36 -0700] "GET /search?query=headache HTTP/1.1" 200 9288
282.482.3 shreyas [10/Oct/2013:13:56:36 -0700] "GET /search?query=bananas HTTP/1.1" 200 2929
345.114.1 steven [10/Oct/2013:13:56:37 -0700] "GET /search?query=cold HTTP/1.1" 200 8232
10.328.52 anne [10/Oct/2013:13:56:39 -0700] "GET /search?query=flu+shot HTTP/1.1" 200 2342
10.328.52 lily [10/Oct/2013:13:57:40 -0700] "GET /search?query=i290 HTTP/1.1" 200 2342
#+end_src

| userName | date | query |
| jim | 10/Oct/2013:13:55:36 -0700 | headache  |
| shreyas | 10/Oct/2013:13:56:36 -0700 | bananas  |
| steven | 10/Oct/2013:13:56:37 -0700 | cold  |
| anne | 10/Oct/2013:13:56:39 -0700 | flu shot  |
| lily | 10/Oct/2013:13:57:40 -0700 | i290  |

*** Imposing Structure :notes:
   + Extract only the rows we know follow a format
   + Format queries from some encoding (eg. URL) to standardized format

** External APIs :slide:
   + Better documented than internal data!
   + More limited in amount and detail
   + Commonly HTTP/REST based
*** Motivation :notes:
   + Companies are often searching for other ways to leverage their data
   + Both for immediate business purposes, and for brand recognition
   + Twitter more (in)famous example
   + NYTimes another good option

** NYTimes API Example :slide:
   + [[http://developer.nytimes.com/docs/read/article_search_api][Article Search API]]
   + http://api.nytimes.com/svc/search/v1/article?format=json&query=ballot&api-key=6578bab7f8c3808ce4c392edc9a793f0:8:5717915
*** Accessing these :notes:
    + More info on how to access these APIs is in the Web Architecture class,
      but feel free to ask Shreyas or I about how best to access them

** Data Sets :slide:
   + Download large, curated set of data all at once
   + Formats vary, but usually documented
   + Can be useful to combine with other datasets or APIs

[[file:img/kaggle-digits.png]]
*** Research :notes:
    + Data sets commonly used in research: can compare different techniques on
      same data to understand advantages
    + Sizes can range to a few MB to GB
    + JSON, CSV, XML all potential formats. Cleaning, organization for your
      question again becomes an important aspect

** Data Set Example :slide:two_col:
   + [[http://www.grouplens.org/node/73][MovieLens Data Sets]]
   + [[https://www.kaggle.com/c/digit-recognizer][Kaggle Digit Recognizer]]
   + [[https://bitly.com/bundles/hmason/1][Hilary Mason's Data Sets]]

[[file:img/video.jpg]]

* Exploring Data :slide:
  + Data sets are frequently too large to fit in standard tools like Excel or
    Word
  + Simplest to explore on the command line
  + Homework will be exploring a data set of your choice
** Size :notes:
   + Some formats will not be easily parsed into Excel: eg. JSON, XML
   + Word will be slow, or unworkable for GB size data
   + CLI provides many composable tools for text manipulation

* Yelp Academic Dataset :slide:
  + [[http://yelp.com/academic_dataset][Yelp Data Set]] covers reviews, users,
    businesses
  + To download, you'll need to sign up: process takes ~24 hours for approval
  + Use .edu email
** Example :notes:
   + We'll use this as an example, you can use any data set of your choice
   + Just for HW, don't need to use for project

* CLI introduction :slide:
  + Standard commands available in [[http://cli.learncodethehardway.com][Learn CLI the hard way]]
  + All example will be run on =ischool.berkeley.edu=
  + Sheyas and I available for more help
** Help :notes:
   + If you're new, don't be intimidated.
   + Security policies ensure you can't break anything besides your own files
   + Keep backups of important stuff anyway

* =wget= :slide:
  + Used for downloading files
  + Downloading with the browser is fine, but sometimes nice to use faster
    connection, or download it directly to machine you're working on
#+begin_src bash
$ wget 'http://www.grouplens.org/system/files/ml-100k.zip'
#+end_src
** Command :notes:
   + Just =wget URL=
   + I like to use quotes in case there are special characters in the URL, eg
     =?=
   + Will download to current directory, same name as remote file

* =scp= :slide:
  + Copy a file to or from a remote machine
  + Uses same connection as SSH, but copies data instead
  + Example: Copy data you've downloaded in your browser
#+begin_src bash
$ scp ~/Downloads/ml-100k.zip jblomo@ischool.berkeley.edu:
# or
$ scp ~/Downloads/ml-100k.zip jblomo@ischool.berkeley.edu:i290/movielens-100k.zip
#+end_src
** Command :notes:
   + Trailing =:= is important: signifies remote machine
   + If you don't specify path or filename, will copy the file with the same
     name into your home directory

* =gunzip= =unzip= :slide:
  + Uncompress data sets for simpler, faster manipulation
#+begin_src bash
$ unzip ml-100k.zip
# or
$ gunzip yelp_academic_dataset.json.gz
#+end_src
** Commands :notes:
   + unzip :: expand potentially many file, leave original alone
   + gunzip :: expand original file, leaving only the uncompressed version

* =less= :slide:
  + View a file
  + History: original command was called =more= to see a file a page at a time
  + "Less is more"
#+begin_src bash
less yelp_academic_dataset.json
#+end_src

* Searching in =less= :slide:
  + =/= (forward slash) lets you input search text
  + =q= will quit
#+begin_src less
/type": "user"
/type": "review"
#+end_src
** Command :notes:
   + Useful for finding specific instances to investigate

* =grep= :slide:
  + Find and print lines matching a "regular expression"
  + [[http://www.regular-expressions.info/quickstart.html][Regular expressions]] are "find" on steroids, but you can use simple strings
#+begin_src bash
$ grep 'type": "review"' yelp_academic_dataset.json
#+end_src

* =wc= :slide:
  + "wordcount" counts characters, words, lines
  + Most useful in data sets for lines: =-l=
#+begin_src bash
$ wc -l yelp_academic_dataset.json
474434 yelp_academic_dataset.json
#+end_src

* Composable :slide:
  + Genius of Unix: do one thing well, compose commands to get what you want
  + =|= pipe characters "sends" output from one program to the input of another
  + How many reviews in the data set?
#+begin_src bash
$ grep 'type": "review"' yelp_academic_dataset.json | wc -l
330071
$ egrep -o 'business_id": "\w+"' yelp_academic_dataset.json  | sort -u | wc -l
9592
#+end_src

#+STYLE: <link rel="stylesheet" type="text/css" href="production/common.css" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/screen.css" media="screen" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/projection.css" media="projection" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/color-blue.css" media="projection" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/presenter.css" media="presenter" />
#+STYLE: <link href='http://fonts.googleapis.com/css?family=Lobster+Two:700|Yanone+Kaffeesatz:700|Open+Sans' rel='stylesheet' type='text/css'>

#+BEGIN_HTML
<script type="text/javascript" src="production/org-html-slideshow.js"></script>
#+END_HTML

# Local Variables:
# org-export-html-style-include-default: nil
# org-export-html-style-include-scripts: nil
# buffer-file-coding-system: utf-8-unix
# End:
